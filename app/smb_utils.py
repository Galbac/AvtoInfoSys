# app/smb_utils.py
import os
from pathlib import Path
from shutil import copy2
from typing import List, Tuple, Dict

from tqdm import tqdm

from app.database import load_state, save_state
from app.hashing import calculate_hash, get_file_info
from app.logger import get_logger

logger = get_logger()


def make_relative_key(source_root: Path, file_path: Path) -> str:
    try:
        rel = file_path.relative_to(source_root)
    except ValueError:
        # –£–Ω–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —á–∞—Å—Ç–∏ –ø—É—Ç–∏
        source_parts = [p.lower().strip("\\/") for p in source_root.parts]
        file_parts = [p.lower().strip("\\/") for p in file_path.parts]
        # –£–¥–∞–ª—è–µ–º –æ–±—â–∏–π –ø—Ä–µ—Ñ–∏–∫—Å
        min_len = min(len(source_parts), len(file_parts))
        i = 0
        while i < min_len and source_parts[i] == file_parts[i]:
            i += 1
        if i > 0:
            rel = Path(*file_parts[i:])
        else:
            rel = Path(*file_parts[1:])  # —É–±–∏—Ä–∞–µ–º \\host
    return os.path.normpath(str(rel)).replace("\\", "/").lower()



def list_files(path: Path) -> List[Path]:
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤."""
    return [f for f in path.rglob("*") if f.is_file()]


def sync_folder(
        name: str,
        source_path: str,
        dest_paths: List[str],
        report_path_root: str,
        dry_run: bool = False
) -> Tuple[List[Tuple[str, str, Dict]], Dict[str, int]]:
    source = Path(source_path)
    logger.info(f"üìÅ –ò—Å—Ç–æ—á–Ω–∏–∫: {source} | –ü—É—Ç—å: {source.resolve() if source.exists() else source}")
    if not source.exists():
        logger.warning(f"‚ö†Ô∏è –ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º): {source}")
        return [], {"added": 0, "modified": 0, "copied": 0}

    if report_path_root:
        report_root = Path(report_path_root) / name
    else:
        report_root = None

    dest_dirs = [Path(p) / name for p in dest_paths]

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫—ç—à
    db = load_state()
    source_cache = db.get(name, {})
    stats = {"added": 0, "modified": 0, "copied": 0}
    changed_files: List[Tuple[str, str, Dict]] = []
    files = list_files(source)

    processed_count = 0
    total_files = len(files)

    with tqdm(
            total=total_files,
            desc=f"üîÑ {name}",
            unit="—Ñ",
            ncols=100,
            leave=False,
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]"
    ) as pbar:
        for src_file in files:
            try:
                relative_path = src_file.relative_to(source)
                target_files = [d / relative_path for d in dest_dirs]
                main_target = report_root / relative_path if report_root else target_files[0]
                src_info = get_file_info(src_file)
                if not src_info:
                    pbar.update(1)
                    continue
                src_mtime, src_size = src_info

                # üîπ –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô –∫–ª—é—á ‚Äî –≤–µ–∑–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è make_relative_key
                rel_path_str = make_relative_key(source, src_file)
                cached = source_cache.get(rel_path_str)

                # üîπ –ü—Ä–æ–≤–µ—Ä–∫–∞: —Ä–∞–∑–º–µ—Ä + mtime —Å –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å—é 5 —Å–µ–∫—É–Ω–¥
                if (cached and
                        cached["size"] == src_size and
                        abs(cached["mtime"] - src_mtime) <= 5.0):
                    src_hash = cached["hash"]
                else:
                    src_hash = calculate_hash(src_file)
                    if not src_hash:
                        pbar.update(1)
                        continue

                # üî• –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
                if name not in db:
                    db[name] = {}
                db[name][rel_path_str] = {
                    "hash": src_hash,
                    "mtime": src_mtime,
                    "size": src_size
                }
                logger.debug(f"üîë –ö–ª—é—á –¥–æ–±–∞–≤–ª–µ–Ω: {rel_path_str} | –§–∞–π–ª: {src_file}")

                # üî• –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–µ 50 —Ñ–∞–π–ª–æ–≤
                processed_count += 1
                if processed_count % 50 == 0:
                    save_state(db)
                    logger.debug(f"üíæ –°–æ—Ö—Ä–∞–Ω—ë–Ω –∫—ç—à –ø–æ—Å–ª–µ {processed_count} —Ñ–∞–π–ª–æ–≤ –≤ '{name}'")

                # üîπ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
                if not main_target.exists():
                    if not dry_run:
                        for dest_file in target_files:
                            dest_file.parent.mkdir(parents=True, exist_ok=True)
                            copy2(src_file, dest_file)
                    stats["added"] += 1
                    stats["copied"] += 1
                    changed_files.append((str(relative_path), "added", {
                        "size": src_size,
                        "mtime": src_mtime
                    }))
                else:
                    old_info = get_file_info(main_target)
                    old_mtime, old_size = old_info if old_info else ("unknown", "unknown")
                    dest_hash = calculate_hash(main_target)
                    if dest_hash and src_hash != dest_hash:
                        if not dry_run:
                            for dest_file in target_files:
                                copy2(src_file, dest_file)
                        stats["modified"] += 1
                        stats["copied"] += 1
                        changed_files.append((str(relative_path), "modified", {
                            "size": src_size,
                            "mtime": src_mtime,
                            "old_size": old_size,
                            "old_mtime": old_mtime
                        }))
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {src_file}: {e}")
            finally:
                pbar.update(1)

    # üîπ –û–ß–ò–°–¢–ö–ê: –∏—Å–ø–æ–ª—å–∑—É–µ–º –¢–£ –ñ–ï —Ñ—É–Ω–∫—Ü–∏—é make_relative_key!
    current_files = {make_relative_key(source, f) for f in files}
    logger.debug(f"üîç –¢–µ–∫—É—â–∏–µ —Ñ–∞–π–ª—ã (–∫–ª—é—á–∏): {len(current_files)}")
    for cf in sorted(current_files):
        logger.debug(f"  üìÑ {cf}")

    if name in db:
        for old_file in list(db[name].keys()):
            if old_file not in current_files:
                logger.warning(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω –∏–∑ –∫—ç—à–∞: '{old_file}' (–Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ–∫—É—â–∏—Ö)")
                del db[name][old_file]
    if name in db:
        total = len(db[name])
        unique = len(set(db[name].keys()))
        if total != unique:
            logger.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏ –∫–ª—é—á–µ–π –≤ '{name}': {total - unique} –¥—É–±–ª–µ–π")

    # üîπ –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    save_state(db)
    logger.info(f"‚úÖ –ö—ç—à –¥–ª—è '{name}' –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")
    return changed_files, stats
